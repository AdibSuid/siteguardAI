# Environment Configuration for SiteGuard AI
# Copy this file to .env and fill in your values

# LLM API Keys
OPENAI_API_KEY=your_openai_api_key_here
GEMINI_API_KEY=your_gemini_api_key_here

# LLM Configuration
LLM_PROVIDER=ollama  # Options: ollama (free), openai, gemini
LLM_MODEL=llama3  # For Ollama: llama3, mistral, phi3 | For OpenAI: gpt-4o | For Gemini: gemini-pro
LLM_TEMPERATURE=0.3
OLLAMA_BASE_URL=http://localhost:11434  # Ollama server URL

# Detection Configuration
YOLO_MODEL_PATH=models/yolov8n.pt
CONFIDENCE_THRESHOLD=0.5
IOU_THRESHOLD=0.45
DEVICE=cpu  # Options: cpu, cuda

# Application Settings
LOG_LEVEL=INFO  # Options: DEBUG, INFO, WARNING, ERROR
VERBOSE=false

# Directories
UPLOADS_DIR=data/uploads
REPORTS_DIR=data/outputs
LOGS_DIR=logs

# API Configuration
API_HOST=0.0.0.0
API_PORT=8000

# Web Dashboard Configuration
WEB_HOST=localhost
WEB_PORT=8501
